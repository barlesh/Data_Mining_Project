{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1> Data Mining Final Project  </center></h1>\n",
    "\n",
    "#### House Sales price ....... \n",
    "##### By : Bar Leshem, Yuval Anavim, Shachar Macharez\n",
    "- Email:    Barlesh8@gmal.com\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'helper_functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4b65abd53e8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mhelper_functions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'helper_functions'"
     ]
    }
   ],
   "source": [
    "#from helper_functions import *\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of contents: \n",
    "\n",
    "- [Introduction: ](#Intro)\n",
    "- [1. Data : cleaning &  filling blank features: ](#1.)\n",
    "    - [1.1. N/A](#1.1.)\n",
    "    - [1.2. Missing cells](#1.2.)\n",
    "- [2. Linear Regression ](#1.)\n",
    "    - [1.1. PCA ](#1.1.)\n",
    "    - [1.2. Linear Models](#1.2.)\n",
    "- [2. Artificial Neural Network](#2.)\n",
    "    - [2.1. sub1](#2.1.)\n",
    "    - [2.2. sub2](#2.2.)    \n",
    "- [Appendix](#Appendix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Intro'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After pushing to github, notebooks can be viewed with http://nbviewer.jupyter.org/ . \n",
    "- You can see this notebook using nbviewer here: http://nbviewer.jupyter.org/github/kaplann/Blank_jupyter_project/blob/master/Blank_proj.ipynb#TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[back to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='#TODO'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Add things to do\n",
    "1. Do things todo  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[back to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path='/home/barlesh/Projects/Data_Mining_Project/data/'\n",
    "train_file='train.csv'\n",
    "test_file='test.csv'\n",
    "train_file_new='train_new.csv'\n",
    "test_file_new='test_new.csv'\n",
    "result_path='results/'\n",
    "result_file='res.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", data_path]).decode(\"utf8\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "houseprice=pd.read_csv(data_path+test_file)\n",
    "houseprice.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a>  1.  Data : Cleaning & filling blank features: </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Lasso\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(data_path+train_file)\n",
    "test = pd.read_csv(data_path+test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_data = pd.concat((train.loc[:,'MSSubClass':'SaleCondition'],\n",
    "                      test.loc[:,'MSSubClass':'SaleCondition']), ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputation of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# I have no idea how to do it better. Probably, it is better to do nothing\n",
    "x = all_data.loc[np.logical_not(all_data[\"LotFrontage\"].isnull()), \"LotArea\"]\n",
    "y = all_data.loc[np.logical_not(all_data[\"LotFrontage\"].isnull()), \"LotFrontage\"]\n",
    "# plt.scatter(x, y)\n",
    "t = (x <= 25000) & (y <= 150)\n",
    "p = np.polyfit(x[t], y[t], 1)\n",
    "all_data.loc[all_data['LotFrontage'].isnull(), 'LotFrontage'] = np.polyval(p, all_data.loc[all_data['LotFrontage'].isnull(), 'LotArea'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data.loc[all_data.Alley.isnull(), 'Alley'] = 'NoAlley'\n",
    "all_data.loc[all_data.MasVnrType.isnull(), 'MasVnrType'] = 'None' # no good\n",
    "all_data.loc[all_data.MasVnrType == 'None', 'MasVnrArea'] = 0\n",
    "all_data.loc[all_data.BsmtQual.isnull(), 'BsmtQual'] = 'NoBsmt'\n",
    "all_data.loc[all_data.BsmtCond.isnull(), 'BsmtCond'] = 'NoBsmt'\n",
    "all_data.loc[all_data.BsmtExposure.isnull(), 'BsmtExposure'] = 'NoBsmt'\n",
    "all_data.loc[all_data.BsmtFinType1.isnull(), 'BsmtFinType1'] = 'NoBsmt'\n",
    "all_data.loc[all_data.BsmtFinType2.isnull(), 'BsmtFinType2'] = 'NoBsmt'\n",
    "all_data.loc[all_data.BsmtFinType1=='NoBsmt', 'BsmtFinSF1'] = 0\n",
    "all_data.loc[all_data.BsmtFinType2=='NoBsmt', 'BsmtFinSF2'] = 0\n",
    "all_data.loc[all_data.BsmtFinSF1.isnull(), 'BsmtFinSF1'] = all_data.BsmtFinSF1.median()\n",
    "all_data.loc[all_data.BsmtQual=='NoBsmt', 'BsmtUnfSF'] = 0\n",
    "all_data.loc[all_data.BsmtUnfSF.isnull(), 'BsmtUnfSF'] = all_data.BsmtUnfSF.median()\n",
    "all_data.loc[all_data.BsmtQual=='NoBsmt', 'TotalBsmtSF'] = 0\n",
    "all_data.loc[all_data.FireplaceQu.isnull(), 'FireplaceQu'] = 'NoFireplace'\n",
    "all_data.loc[all_data.GarageType.isnull(), 'GarageType'] = 'NoGarage'\n",
    "all_data.loc[all_data.GarageFinish.isnull(), 'GarageFinish'] = 'NoGarage'\n",
    "all_data.loc[all_data.GarageQual.isnull(), 'GarageQual'] = 'NoGarage'\n",
    "all_data.loc[all_data.GarageCond.isnull(), 'GarageCond'] = 'NoGarage'\n",
    "all_data.loc[all_data.BsmtFullBath.isnull(), 'BsmtFullBath'] = 0\n",
    "all_data.loc[all_data.BsmtHalfBath.isnull(), 'BsmtHalfBath'] = 0\n",
    "all_data.loc[all_data.KitchenQual.isnull(), 'KitchenQual'] = 'TA'\n",
    "all_data.loc[all_data.MSZoning.isnull(), 'MSZoning'] = 'RL'\n",
    "all_data.loc[all_data.Utilities.isnull(), 'Utilities'] = 'AllPub'\n",
    "all_data.loc[all_data.Exterior1st.isnull(), 'Exterior1st'] = 'VinylSd'\n",
    "all_data.loc[all_data.Exterior2nd.isnull(), 'Exterior2nd'] = 'VinylSd'\n",
    "all_data.loc[all_data.Functional.isnull(), 'Functional'] = 'Typ'\n",
    "all_data.loc[all_data.SaleCondition.isnull(), 'SaleCondition'] = 'Normal'\n",
    "all_data.loc[all_data.SaleCondition.isnull(), 'SaleType'] = 'WD'\n",
    "all_data.loc[all_data['PoolQC'].isnull(), 'PoolQC'] = 'NoPool'\n",
    "all_data.loc[all_data['Fence'].isnull(), 'Fence'] = 'NoFence'\n",
    "all_data.loc[all_data['MiscFeature'].isnull(), 'MiscFeature'] = 'None'\n",
    "all_data.loc[all_data['Electrical'].isnull(), 'Electrical'] = 'SBrkr'\n",
    "# only one is null and it has type Detchd\n",
    "all_data.loc[all_data['GarageArea'].isnull(), 'GarageArea'] = all_data.loc[all_data['GarageType']=='Detchd', 'GarageArea'].mean()\n",
    "all_data.loc[all_data['GarageCars'].isnull(), 'GarageCars'] = all_data.loc[all_data['GarageType']=='Detchd', 'GarageCars'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# where we have order we will use numeric\n",
    "all_data = all_data.replace({'Utilities': {'AllPub': 1, 'NoSeWa': 0, 'NoSewr': 0, 'ELO': 0},\n",
    "                             'Street': {'Pave': 1, 'Grvl': 0 },\n",
    "                             'FireplaceQu': {'Ex': 5, \n",
    "                                            'Gd': 4, \n",
    "                                            'TA': 3, \n",
    "                                            'Fa': 2,\n",
    "                                            'Po': 1,\n",
    "                                            'NoFireplace': 0 \n",
    "                                            },\n",
    "                             'Fence': {'GdPrv': 2, \n",
    "                                       'GdWo': 2, \n",
    "                                       'MnPrv': 1, \n",
    "                                       'MnWw': 1,\n",
    "                                       'NoFence': 0},\n",
    "                             'ExterQual': {'Ex': 5, \n",
    "                                            'Gd': 4, \n",
    "                                            'TA': 3, \n",
    "                                            'Fa': 2,\n",
    "                                            'Po': 1\n",
    "                                            },\n",
    "                             'ExterCond': {'Ex': 5, \n",
    "                                            'Gd': 4, \n",
    "                                            'TA': 3, \n",
    "                                            'Fa': 2,\n",
    "                                            'Po': 1\n",
    "                                            },\n",
    "                             'BsmtQual': {'Ex': 5, \n",
    "                                            'Gd': 4, \n",
    "                                            'TA': 3, \n",
    "                                            'Fa': 2,\n",
    "                                            'Po': 1,\n",
    "                                            'NoBsmt': 0},\n",
    "                             'BsmtExposure': {'Gd': 3, \n",
    "                                            'Av': 2, \n",
    "                                            'Mn': 1,\n",
    "                                            'No': 0,\n",
    "                                            'NoBsmt': 0},\n",
    "                             'BsmtCond': {'Ex': 5, \n",
    "                                            'Gd': 4, \n",
    "                                            'TA': 3, \n",
    "                                            'Fa': 2,\n",
    "                                            'Po': 1,\n",
    "                                            'NoBsmt': 0},\n",
    "                             'GarageQual': {'Ex': 5, \n",
    "                                            'Gd': 4, \n",
    "                                            'TA': 3, \n",
    "                                            'Fa': 2,\n",
    "                                            'Po': 1,\n",
    "                                            'NoGarage': 0},\n",
    "                             'GarageCond': {'Ex': 5, \n",
    "                                            'Gd': 4, \n",
    "                                            'TA': 3, \n",
    "                                            'Fa': 2,\n",
    "                                            'Po': 1,\n",
    "                                            'NoGarage': 0},\n",
    "                             'KitchenQual': {'Ex': 5, \n",
    "                                            'Gd': 4, \n",
    "                                            'TA': 3, \n",
    "                                            'Fa': 2,\n",
    "                                            'Po': 1},\n",
    "                             'Functional': {'Typ': 0,\n",
    "                                            'Min1': 1,\n",
    "                                            'Min2': 1,\n",
    "                                            'Mod': 2,\n",
    "                                            'Maj1': 3,\n",
    "                                            'Maj2': 4,\n",
    "                                            'Sev': 5,\n",
    "                                            'Sal': 6}                             \n",
    "                            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newer_dwelling = all_data.MSSubClass.replace({20: 1, \n",
    "                                            30: 0, \n",
    "                                            40: 0, \n",
    "                                            45: 0,\n",
    "                                            50: 0, \n",
    "                                            60: 1,\n",
    "                                            70: 0,\n",
    "                                            75: 0,\n",
    "                                            80: 0,\n",
    "                                            85: 0,\n",
    "                                            90: 0,\n",
    "                                           120: 1,\n",
    "                                           150: 0,\n",
    "                                           160: 0,\n",
    "                                           180: 0,\n",
    "                                           190: 0})\n",
    "newer_dwelling.name = 'newer_dwelling'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data = all_data.replace({'MSSubClass': {20: 'SubClass_20', \n",
    "                                            30: 'SubClass_30', \n",
    "                                            40: 'SubClass_40', \n",
    "                                            45: 'SubClass_45',\n",
    "                                            50: 'SubClass_50', \n",
    "                                            60: 'SubClass_60',\n",
    "                                            70: 'SubClass_70',\n",
    "                                            75: 'SubClass_75',\n",
    "                                            80: 'SubClass_80',\n",
    "                                            85: 'SubClass_85',\n",
    "                                            90: 'SubClass_90',\n",
    "                                           120: 'SubClass_120',\n",
    "                                           150: 'SubClass_150',\n",
    "                                           160: 'SubClass_160',\n",
    "                                           180: 'SubClass_180',\n",
    "                                           190: 'SubClass_190'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The idea is good quality should rise price, poor quality - reduce price\n",
    "overall_poor_qu = all_data.OverallQual.copy()\n",
    "overall_poor_qu = 5 - overall_poor_qu\n",
    "overall_poor_qu[overall_poor_qu<0] = 0\n",
    "overall_poor_qu.name = 'overall_poor_qu'\n",
    "\n",
    "overall_good_qu = all_data.OverallQual.copy()\n",
    "overall_good_qu = overall_good_qu - 5\n",
    "overall_good_qu[overall_good_qu<0] = 0\n",
    "overall_good_qu.name = 'overall_good_qu'\n",
    "\n",
    "overall_poor_cond = all_data.OverallCond.copy()\n",
    "overall_poor_cond = 5 - overall_poor_cond\n",
    "overall_poor_cond[overall_poor_cond<0] = 0\n",
    "overall_poor_cond.name = 'overall_poor_cond'\n",
    "\n",
    "overall_good_cond = all_data.OverallCond.copy()\n",
    "overall_good_cond = overall_good_cond - 5\n",
    "overall_good_cond[overall_good_cond<0] = 0\n",
    "overall_good_cond.name = 'overall_good_cond'\n",
    "\n",
    "exter_poor_qu = all_data.ExterQual.copy()\n",
    "exter_poor_qu[exter_poor_qu<3] = 1\n",
    "exter_poor_qu[exter_poor_qu>=3] = 0\n",
    "exter_poor_qu.name = 'exter_poor_qu'\n",
    "\n",
    "exter_good_qu = all_data.ExterQual.copy()\n",
    "exter_good_qu[exter_good_qu<=3] = 0\n",
    "exter_good_qu[exter_good_qu>3] = 1\n",
    "exter_good_qu.name = 'exter_good_qu'\n",
    "\n",
    "exter_poor_cond = all_data.ExterCond.copy()\n",
    "exter_poor_cond[exter_poor_cond<3] = 1\n",
    "exter_poor_cond[exter_poor_cond>=3] = 0\n",
    "exter_poor_cond.name = 'exter_poor_cond'\n",
    "\n",
    "exter_good_cond = all_data.ExterCond.copy()\n",
    "exter_good_cond[exter_good_cond<=3] = 0\n",
    "exter_good_cond[exter_good_cond>3] = 1\n",
    "exter_good_cond.name = 'exter_good_cond'\n",
    "\n",
    "bsmt_poor_cond = all_data.BsmtCond.copy()\n",
    "bsmt_poor_cond[bsmt_poor_cond<3] = 1\n",
    "bsmt_poor_cond[bsmt_poor_cond>=3] = 0\n",
    "bsmt_poor_cond.name = 'bsmt_poor_cond'\n",
    "\n",
    "bsmt_good_cond = all_data.BsmtCond.copy()\n",
    "bsmt_good_cond[bsmt_good_cond<=3] = 0\n",
    "bsmt_good_cond[bsmt_good_cond>3] = 1\n",
    "bsmt_good_cond.name = 'bsmt_good_cond'\n",
    "\n",
    "garage_poor_qu = all_data.GarageQual.copy()\n",
    "garage_poor_qu[garage_poor_qu<3] = 1\n",
    "garage_poor_qu[garage_poor_qu>=3] = 0\n",
    "garage_poor_qu.name = 'garage_poor_qu'\n",
    "\n",
    "garage_good_qu = all_data.GarageQual.copy()\n",
    "garage_good_qu[garage_good_qu<=3] = 0\n",
    "garage_good_qu[garage_good_qu>3] = 1\n",
    "garage_good_qu.name = 'garage_good_qu'\n",
    "\n",
    "garage_poor_cond = all_data.GarageCond.copy()\n",
    "garage_poor_cond[garage_poor_cond<3] = 1\n",
    "garage_poor_cond[garage_poor_cond>=3] = 0\n",
    "garage_poor_cond.name = 'garage_poor_cond'\n",
    "\n",
    "garage_good_cond = all_data.GarageCond.copy()\n",
    "garage_good_cond[garage_good_cond<=3] = 0\n",
    "garage_good_cond[garage_good_cond>3] = 1\n",
    "garage_good_cond.name = 'garage_good_cond'\n",
    "\n",
    "kitchen_poor_qu = all_data.KitchenQual.copy()\n",
    "kitchen_poor_qu[kitchen_poor_qu<3] = 1\n",
    "kitchen_poor_qu[kitchen_poor_qu>=3] = 0\n",
    "kitchen_poor_qu.name = 'kitchen_poor_qu'\n",
    "\n",
    "kitchen_good_qu = all_data.KitchenQual.copy()\n",
    "kitchen_good_qu[kitchen_good_qu<=3] = 0\n",
    "kitchen_good_qu[kitchen_good_qu>3] = 1\n",
    "kitchen_good_qu.name = 'kitchen_good_qu'\n",
    "\n",
    "qu_list = pd.concat((overall_poor_qu, overall_good_qu, overall_poor_cond, overall_good_cond, exter_poor_qu,\n",
    "                     exter_good_qu, exter_poor_cond, exter_good_cond, bsmt_poor_cond, bsmt_good_cond, garage_poor_qu,\n",
    "                     garage_good_qu, garage_poor_cond, garage_good_cond, kitchen_poor_qu, kitchen_good_qu), axis=1)\n",
    "\n",
    "bad_heating = all_data.HeatingQC.replace({'Ex': 0, \n",
    "                                          'Gd': 0, \n",
    "                                          'TA': 0, \n",
    "                                          'Fa': 1,\n",
    "                                          'Po': 1})\n",
    "bad_heating.name = 'bad_heating'\n",
    "                                          \n",
    "MasVnrType_Any = all_data.MasVnrType.replace({'BrkCmn': 1,\n",
    "                                              'BrkFace': 1,\n",
    "                                              'CBlock': 1,\n",
    "                                              'Stone': 1,\n",
    "                                              'None': 0})\n",
    "MasVnrType_Any.name = 'MasVnrType_Any'\n",
    "\n",
    "SaleCondition_PriceDown = all_data.SaleCondition.replace({'Abnorml': 1,\n",
    "                                                          'Alloca': 1,\n",
    "                                                          'AdjLand': 1,\n",
    "                                                          'Family': 1,\n",
    "                                                          'Normal': 0,\n",
    "                                                          'Partial': 0})\n",
    "SaleCondition_PriceDown.name = 'SaleCondition_PriceDown'\n",
    "\n",
    "Neighborhood_Good = pd.DataFrame(np.zeros((all_data.shape[0],1)), columns=['Neighborhood_Good'])\n",
    "Neighborhood_Good[all_data.Neighborhood=='NridgHt'] = 1\n",
    "Neighborhood_Good[all_data.Neighborhood=='Crawfor'] = 1\n",
    "Neighborhood_Good[all_data.Neighborhood=='StoneBr'] = 1\n",
    "Neighborhood_Good[all_data.Neighborhood=='Somerst'] = 1\n",
    "Neighborhood_Good[all_data.Neighborhood=='NoRidge'] = 1\n",
    "\n",
    "# do smth with BsmtFinType1, BsmtFinType2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have no idea what to do with Exterior1st, Exterior2nd, RoofMatl, Condition1, Condition2, BldgType. I'll try convert them into some kind of price brackets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC(C=100)\n",
    "# price categories\n",
    "pc = pd.Series(np.zeros(train.shape[0]))\n",
    "pc[:] = 'pc1'\n",
    "pc[train.SalePrice >= 150000] = 'pc2'\n",
    "pc[train.SalePrice >= 220000] = 'pc3'\n",
    "columns_for_pc = ['Exterior1st', 'Exterior2nd', 'RoofMatl', 'Condition1', 'Condition2', 'BldgType']\n",
    "X_t = pd.get_dummies(train.loc[:, columns_for_pc], sparse=True)\n",
    "svm.fit(X_t, pc)\n",
    "pc_pred = svm.predict(X_t)\n",
    "print(pc_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = train.SalePrice/100000\n",
    "plt.hist(p[pc_pred=='pc1'])\n",
    "plt.hist(p[pc_pred=='pc2'])\n",
    "plt.hist(p[pc_pred=='pc3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "price_category = pd.DataFrame(np.zeros((all_data.shape[0],1)), columns=['pc'])\n",
    "X_t = pd.get_dummies(all_data.loc[:, columns_for_pc], sparse=True)\n",
    "pc_pred = svm.predict(X_t)\n",
    "price_category[pc_pred=='pc2'] = 1\n",
    "price_category[pc_pred=='pc3'] = 2\n",
    "price_category = price_category.to_sparse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Monthes with the lagest number of deals may be significant\n",
    "season = all_data.MoSold.replace( {1: 0, \n",
    "                                   2: 0, \n",
    "                                   3: 0, \n",
    "                                   4: 1,\n",
    "                                   5: 1, \n",
    "                                   6: 1,\n",
    "                                   7: 1,\n",
    "                                   8: 0,\n",
    "                                   9: 0,\n",
    "                                  10: 0,\n",
    "                                  11: 0,\n",
    "                                  12: 0})\n",
    "season.name = 'season'\n",
    "\n",
    "# Numer month is not significant\n",
    "all_data = all_data.replace({'MoSold': {1: 'Yan', \n",
    "                                        2: 'Feb', \n",
    "                                        3: 'Mar', \n",
    "                                        4: 'Apr',\n",
    "                                        5: 'May', \n",
    "                                        6: 'Jun',\n",
    "                                        7: 'Jul',\n",
    "                                        8: 'Avg',\n",
    "                                        9: 'Sep',\n",
    "                                        10: 'Oct',\n",
    "                                        11: 'Nov',\n",
    "                                        12: 'Dec'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data = all_data.replace({'CentralAir': {'Y': 1, \n",
    "                                            'N': 0}})\n",
    "all_data = all_data.replace({'PavedDrive': {'Y': 1, \n",
    "                                            'P': 0,\n",
    "                                            'N': 0}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "reconstruct = pd.DataFrame(np.zeros((all_data.shape[0],1)), columns=['Reconstruct'])\n",
    "reconstruct[all_data.YrSold < all_data.YearRemodAdd] = 1\n",
    "reconstruct = reconstruct.to_sparse()\n",
    "\n",
    "recon_after_buy = pd.DataFrame(np.zeros((all_data.shape[0],1)), columns=['ReconstructAfterBuy'])\n",
    "recon_after_buy[all_data.YearRemodAdd >= all_data.YrSold] = 1\n",
    "recon_after_buy = recon_after_buy.to_sparse()\n",
    "\n",
    "build_eq_buy = pd.DataFrame(np.zeros((all_data.shape[0],1)), columns=['Build.eq.Buy'])\n",
    "build_eq_buy[all_data.YearBuilt >= all_data.YrSold] = 1\n",
    "build_eq_buy = build_eq_buy.to_sparse()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# I hope this will help\n",
    "all_data.YrSold = 2010 - all_data.YrSold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "year_map = pd.concat(pd.Series('YearGroup' + str(i+1), index=range(1871+i*20,1891+i*20)) for i in range(0, 7))\n",
    "all_data.GarageYrBlt = all_data.GarageYrBlt.map(year_map)\n",
    "all_data.loc[all_data['GarageYrBlt'].isnull(), 'GarageYrBlt'] = 'NoGarage'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "all_data.YearBuilt = all_data.YearBuilt.map(year_map)\n",
    "all_data.YearRemodAdd = all_data.YearRemodAdd.map(year_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index\n",
    "\n",
    "t = all_data[numeric_feats].quantile(.95)\n",
    "#print(t)\n",
    "use_max_scater = t[t == 0].index\n",
    "use_95_scater = t[t != 0].index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(t)\n",
    "#print(use_95_scater)\n",
    "#print(use_max_scater)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize data closer to 0 (divide by max value, so all value are at range [0,1])\n",
    "all_data[use_max_scater] = all_data[use_max_scater]/all_data[use_max_scater].max()\n",
    "# normalize data closer to 0 (divide by max value (of 95%), so all value are at range [0,1])\n",
    "all_data[use_95_scater] = all_data[use_95_scater]/all_data[use_95_scater].quantile(.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# option 1 - Author's choice\n",
    "t = ['LotFrontage', 'LotArea', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', \n",
    "     '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', \n",
    "     'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal']\n",
    "\n",
    "# option 2 - all numarical fetures\n",
    "#t = all_data.dtypes[all_data.dtypes != \"object\"].index\n",
    "print(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data.loc[:, t] = np.log1p(all_data.loc[:, t])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing for sklearn##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all classes in sklearn requires numeric data only\n",
    "# transform categorical variable into binary\n",
    "X = pd.get_dummies(all_data, sparse=True)\n",
    "X = X.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = X.drop('RoofMatl_ClyTile', axis=1) # only one is not zero\n",
    "X = X.drop('Condition2_PosN', axis=1) # only two is not zero\n",
    "X = X.drop('MSZoning_C (all)', axis=1)\n",
    "X = X.drop('MSSubClass_SubClass_160', axis=1)\n",
    "# this features definitely couse overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add new features\n",
    "X = pd.concat((X, newer_dwelling, season, reconstruct, recon_after_buy,\n",
    "               qu_list, bad_heating, MasVnrType_Any, price_category, build_eq_buy), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import product, chain\n",
    "\n",
    "def poly(X):\n",
    "    areas = ['LotArea', 'TotalBsmtSF', 'GrLivArea', 'GarageArea', 'BsmtUnfSF']\n",
    "    # t = [s for s in X.axes[1].get_values() if s not in areas]\n",
    "    t = chain(qu_list.axes[1].get_values(), \n",
    "              ['OverallQual', 'OverallCond', 'ExterQual', 'ExterCond', 'BsmtCond', 'GarageQual', 'GarageCond',\n",
    "               'KitchenQual', 'HeatingQC', 'bad_heating', 'MasVnrType_Any', 'SaleCondition_PriceDown', 'Reconstruct',\n",
    "               'ReconstructAfterBuy', 'Build.eq.Buy'])\n",
    "    for a, t in product(areas, t):\n",
    "        x = X.loc[:, [a, t]].prod(1)\n",
    "        x.name = a + '_' + t\n",
    "        yield x\n",
    "\n",
    "XP = pd.concat(poly(X), axis=1)\n",
    "X = pd.concat((X, XP), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = X[:train.shape[0]]\n",
    "X_test = X[train.shape[0]:]\n",
    "#print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the model has become really big\n",
    "X_train.shape\n",
    "#print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.log1p(train.SalePrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# this come from iterational model improvment. I was trying to understand why the model gives to the two points much better price\n",
    "x_plot = X_train.loc[X_train['SaleCondition_Partial']==1, 'GrLivArea']\n",
    "y_plot = y[X_train['SaleCondition_Partial']==1]\n",
    "plt.scatter(x_plot, y_plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "outliers_id = np.array([524, 1299])\n",
    "\n",
    "outliers_id = outliers_id - 1 # id starts with 1, index starts with 0\n",
    "X_train = X_train.drop(outliers_id)\n",
    "y = y.drop(outliers_id)\n",
    "# There are difinetly more outliers\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Methods #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "\n",
    "def rmsle(y, y_pred):\n",
    "     return np.sqrt((( (np.log1p(y_pred*price_scale)- np.log1p(y*price_scale)) )**2).mean())\n",
    "\n",
    "# scorer = make_scorer(rmsle, False)\n",
    "scorer = make_scorer(mean_squared_error, False)\n",
    "\n",
    "def rmse_cv(model, X, y):\n",
    "     return (cross_val_score(model, X, y, scoring=scorer)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA & Linear Reggression #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import datasets, linear_model\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regr.fit(X_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The coefficients\n",
    "#print('Coefficients: \\n', regr.coef_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(\"Mean squared error: %.2f\"\n",
    "#      % np.mean((regr.predict(X_train) - y) ** 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Explained variance score: 1 is perfect prediction\n",
    "#print('Variance score: %.2f' % regr.score(X_train, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = abs(regr.predict(X_test))\n",
    "print (pred)\n",
    "print(max(pred))\n",
    "print(min(pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pred = np.expm1(pred) \n",
    "#pred = (regr.predict(X_test))\n",
    "preds =pred\n",
    "solution = pd.DataFrame({\"id\":test.Id, \"SalePrice\":preds})\n",
    "solution.to_csv(data_path+result_path+\"lreg_results.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso & Reggression #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alphas = [1e-4, 6e-4, 1e-3, 5e-3]\n",
    "cv_lasso = [rmse_cv(Lasso(alpha = alpha, max_iter=150000), X_train, y) for alpha in alphas]\n",
    "pd.Series(cv_lasso, index = alphas).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose alpha with better score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_lasso = Lasso(alpha=5e-4, max_iter=1150000).fit(X_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This is a good way to see how model predict data\n",
    "p_pred = np.expm1(model_lasso.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#p_pred = abs(regr.predict(X_test))\n",
    "#print (p_pred)\n",
    "#print(max(p_pred))\n",
    "#print(min(p_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#plt.scatter(p_pred, np.expm1(y))\n",
    "#plt.plot([min(p_pred),max(p_pred)], [min(p_pred),max(p_pred)], c=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some point are far from the red line. May be they are outliers like the 524th and the 1299th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save to file to make a submission\n",
    "p = np.expm1(model_lasso.predict(X_test))\n",
    "solution = pd.DataFrame({\"id\":test.Id, \"SalePrice\":p}, columns=['id', 'SalePrice'])\n",
    "solution.to_csv(data_path+result_path+\"lasso_result.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rmse_cv(model):\n",
    "    rmse= np.sqrt(-cross_val_score(model, X_train, y, scoring=\"neg_mean_squared_error\", cv = 5))\n",
    "    return(rmse)\n",
    "\n",
    "cv_rmse_lasso = rmse_cv(model_lasso).mean()\n",
    "print (cv_rmse_lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def rmse_cv(model):\n",
    "#    rmse= np.sqrt(-cross_val_score(model, X_train, y, scoring=\"neg_mean_squared_error\", cv = 5))\n",
    "#    return(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "model_svm = svm.SVR(kernel=\"rbf\", C=1,)\n",
    "model_svm.fit(X_train, y)\n",
    "\n",
    "cv_rmse_svm = rmse_cv(model_svm).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (cv_rmse_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm_preds = np.expm1(model_svm.predict(X_test))\n",
    "preds =svm_preds\n",
    "solution = pd.DataFrame({\"id\":test.Id, \"SalePrice\":preds})\n",
    "solution.to_csv(data_path+result_path+\"svm_results.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[back to top](#top)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.2.'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[back to top](#top)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[back to top](#top)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.1.'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[back to top](#top)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[back to top](#top)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Appendix'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[back to top](#top)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Great tutorials: \n",
    " - 1) \n",
    " - 2) \n",
    "- Refferences: \n",
    " - 1) \n",
    "- Resources: \n",
    " - \n",
    " - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[back to top](#top)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
