{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The idea is:**\n",
    "\n",
    " - Feature reduction with PCA\n",
    " - Data transformation (log, hot encoding, nan)\n",
    " - Test different regression models\n",
    "\n",
    "**Things found:**\n",
    "\n",
    "- Applying log transformation really increases the accuracy.\n",
    "- Using PCA with 36 components makes the learning and testing much (much much) faster.\n",
    "- Removing columns with more than 1000 NaNs gives better result than applying \"mean\" to them.\n",
    "- There are outliers. Instead of removing them, using Huber seems to provide a good result. Huber is a model robust to outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "#import tflearn\n",
    "#import tensorflow as tf\n",
    "import seaborn\n",
    "import warnings\n",
    "import subprocess\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from subprocess import check_output\n",
    "#subprocess.check_output([\"ls\",\"C:/Users/yuvalanavim/Desktop/test_regrission\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path='/home/barlesh/Projects/Data_Mining_Project/data/'\n",
    "train_file='train.csv'\n",
    "test_file='test.csv'\n",
    "train_file_new='train_new.csv'\n",
    "test_file_new='test_new.csv'\n",
    "result_path='results/'\n",
    "result_file='res.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Load ##\n",
    "\n",
    "I mix data and test to manipulate all the data just once. SalePrice is extracted to its own variable \"labels\". Finally, SalesPrice is remove from data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(data_path+train_file_new)\n",
    "labels=train[\"SalePrice\"]\n",
    "test = pd.read_csv(data_path+test_file_new)\n",
    "data = pd.concat([train,test],ignore_index=True)\n",
    "data = data.drop(\"SalePrice\", 1)\n",
    "ids = test[\"Id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>0</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>0</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>0</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>0</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>0</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Id  MSSubClass MSZoning  LotFrontage  LotArea Street  Alley  \\\n",
       "0           0   1          60       RL         65.0     8450   Pave      0   \n",
       "1           1   2          20       RL         80.0     9600   Pave      0   \n",
       "2           2   3          60       RL         68.0    11250   Pave      0   \n",
       "3           3   4          70       RL         60.0     9550   Pave      0   \n",
       "4           4   5          60       RL         84.0    14260   Pave      0   \n",
       "\n",
       "  LotShape LandContour    ...     PoolArea PoolQC Fence MiscFeature MiscVal  \\\n",
       "0      Reg         Lvl    ...            0   None  None        None       0   \n",
       "1      Reg         Lvl    ...            0   None  None        None       0   \n",
       "2      IR1         Lvl    ...            0   None  None        None       0   \n",
       "3      IR1         Lvl    ...            0   None  None        None       0   \n",
       "4      IR1         Lvl    ...            0   None  None        None       0   \n",
       "\n",
       "  MoSold YrSold SaleType  SaleCondition  SalePrice  \n",
       "0      2   2008       WD         Normal     208500  \n",
       "1      5   2007       WD         Normal     181500  \n",
       "2      9   2008       WD         Normal     223500  \n",
       "3      2   2006       WD        Abnorml     140000  \n",
       "4     12   2008       WD         Normal     250000  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1460"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of rows in train\n",
    "train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2919"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of rows in total\n",
    "data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of NaNs each column has.\n",
    "nans=pd.isnull(data).sum()\n",
    "nans[nans>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove id and columns with more than a thousand missing values\n",
    "#data=data.drop(\"Id\", 1)\n",
    "#data=data.drop(\"Alley\", 1)\n",
    "#data=data.drop(\"Fence\", 1)\n",
    "#data=data.drop(\"MiscFeature\", 1)\n",
    "#data=data.drop(\"PoolQC\", 1)\n",
    "#data=data.drop(\"FireplaceQu\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "object     44\n",
       "int64      28\n",
       "float64     9\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the column types\n",
    "data.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Manipulation ##\n",
    "\n",
    "- Apply hot encoding, convert categorical variable into dummy/indicator variables.\n",
    "- Fill NaN with median for that column.\n",
    "- Log transformation.\n",
    "- Change -inf to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_columns = data.columns.values\n",
    "non_categorical = [\"LotFrontage\", \"LotArea\", \"MasVnrArea\", \"BsmtFinSF1\", \n",
    "                   \"BsmtFinSF2\", \"BsmtUnfSF\", \"TotalBsmtSF\", \"1stFlrSF\", \n",
    "                   \"2ndFlrSF\", \"LowQualFinSF\", \"GrLivArea\", \"GarageArea\", \n",
    "                   \"WoodDeckSF\", \"OpenPorchSF\", \"EnclosedPorch\", \"3SsnPorch\", \n",
    "                   \"ScreenPorch\",\"PoolArea\", \"MiscVal\"]\n",
    "\n",
    "categorical = [value for value in all_columns if value not in non_categorical]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# One Hot Encoding and nan transformation\n",
    "data = pd.get_dummies(data)\n",
    "\n",
    "imp = Imputer(missing_values='NaN', strategy='most_frequent', axis=0)\n",
    "data = imp.fit_transform(data)\n",
    "\n",
    "# Log transformation\n",
    "data = np.log1p(data)\n",
    "labels = np.log1p(labels)\n",
    "\n",
    "# Change -inf to 0 again\n",
    "data[data==-np.inf]=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature reduction ##\n",
    "\n",
    "There are many features, so I am going to use PCA to reduce them. The idea is to start with n_components = number of columns. Then select the number of components that add up to 1 variance_ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.19760458,  0.35926126,  0.46224055,  0.54787041,  0.61663246,\n",
       "        0.67687481,  0.72556865,  0.76598861,  0.79627022,  0.82057729,\n",
       "        0.84336107,  0.86289941,  0.87293647,  0.88216824,  0.89088168,\n",
       "        0.89736578,  0.90258448,  0.9076625 ,  0.91230965,  0.91622932,\n",
       "        0.91945689,  0.92229119,  0.92491808,  0.92746359,  0.92983136,\n",
       "        0.93192809,  0.93398991,  0.9360133 ,  0.93797388,  0.93981181,\n",
       "        0.94155563,  0.94324449,  0.94492936,  0.94650402,  0.94804956,\n",
       "        0.94952207,  0.95096716,  0.952375  ,  0.95374932,  0.95502035,\n",
       "        0.95626247,  0.95744185,  0.95859983,  0.95974299,  0.96084951,\n",
       "        0.96189092,  0.96291092,  0.96391498,  0.96488338,  0.96580461,\n",
       "        0.96671531,  0.9675925 ,  0.96844572,  0.96927717,  0.97009185,\n",
       "        0.97086426,  0.97161593,  0.97234783,  0.97305419,  0.97375171,\n",
       "        0.97443489,  0.97509531,  0.97574272,  0.97637504,  0.97700014,\n",
       "        0.97759163,  0.97817923,  0.97874236,  0.97926415,  0.97977874,\n",
       "        0.98028797,  0.98077878,  0.98124563,  0.98169994,  0.98213176,\n",
       "        0.98255849,  0.98297363,  0.98337951,  0.98377007,  0.9841591 ,\n",
       "        0.98453028,  0.9848953 ,  0.98524506,  0.98557847,  0.98590704,\n",
       "        0.98622831,  0.98654572,  0.98684149,  0.98713319,  0.98741937,\n",
       "        0.98770299,  0.98798306,  0.98825369,  0.98852249,  0.98878513,\n",
       "        0.98904192,  0.98929614,  0.98954926,  0.98979893,  0.99003995,\n",
       "        0.99027809,  0.99050882,  0.99073695,  0.99095883,  0.99117338,\n",
       "        0.99138536,  0.99159451,  0.99179975,  0.99200125,  0.99219675,\n",
       "        0.99238451,  0.99256958,  0.992751  ,  0.99292835,  0.99309983,\n",
       "        0.99326722,  0.99343168,  0.99359448,  0.99375542,  0.99391379,\n",
       "        0.99406884,  0.99422163,  0.99437111,  0.99451589,  0.99465961,\n",
       "        0.99479819,  0.99493305,  0.9950662 ,  0.99519546,  0.99532083,\n",
       "        0.99544074,  0.99555996,  0.99567619,  0.99578785,  0.99589846,\n",
       "        0.99600571,  0.99611132,  0.99621547,  0.9963158 ,  0.9964123 ,\n",
       "        0.9965077 ,  0.99660152,  0.99669355,  0.99678299,  0.99687028,\n",
       "        0.99695564,  0.99704003,  0.99712222,  0.9972005 ,  0.99727628,\n",
       "        0.99735126,  0.99742276,  0.99749335,  0.997563  ,  0.9976309 ,\n",
       "        0.99769693,  0.99776128,  0.99782408,  0.99788511,  0.99794537,\n",
       "        0.99800375,  0.99806086,  0.99811572,  0.99816983,  0.99822356,\n",
       "        0.99827583,  0.99832675,  0.99837622,  0.99842517,  0.99847297,\n",
       "        0.9985182 ,  0.99856286,  0.99860674,  0.99864982,  0.99869149,\n",
       "        0.99873236,  0.99877187,  0.99881032,  0.99884837,  0.99888526,\n",
       "        0.99892191,  0.99895768,  0.99899246,  0.99902679,  0.99906046,\n",
       "        0.99909359,  0.99912612,  0.99915712,  0.99918763,  0.99921695,\n",
       "        0.99924596,  0.99927389,  0.99930046,  0.99932612,  0.99935115,\n",
       "        0.99937603,  0.99940014,  0.99942278,  0.9994448 ,  0.99946559,\n",
       "        0.99948595,  0.99950617,  0.99952495,  0.99954308,  0.99956066,\n",
       "        0.99957788,  0.99959462,  0.99961101,  0.9996272 ,  0.99964308,\n",
       "        0.99965857,  0.99967256,  0.99968613,  0.9996992 ,  0.99971206,\n",
       "        0.99972447,  0.99973662,  0.99974861,  0.99976015,  0.99977153,\n",
       "        0.99978257,  0.99979324,  0.99980335,  0.99981239,  0.99982133,\n",
       "        0.99983017,  0.99983878,  0.99984684,  0.99985481,  0.99986261,\n",
       "        0.9998701 ,  0.99987723,  0.99988427,  0.99989081,  0.99989655,\n",
       "        0.99990203,  0.99990731,  0.99991247,  0.99991739,  0.99992227,\n",
       "        0.99992703,  0.99993166,  0.99993622,  0.99994065,  0.999945  ,\n",
       "        0.99994915,  0.9999527 ,  0.9999558 ,  0.99995871,  0.99996142,\n",
       "        0.99996411,  0.9999667 ,  0.99996927,  0.99997174,  0.99997418,\n",
       "        0.99997655,  0.99997888,  0.99998119,  0.99998344,  0.99998566,\n",
       "        0.99998778,  0.9999896 ,  0.99999132,  0.99999292,  0.99999447,\n",
       "        0.99999596,  0.99999722,  0.9999983 ,  0.99999914,  0.99999963,\n",
       "        0.99999989,  0.99999998,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(whiten=True)\n",
    "pca.fit(data)\n",
    "variance = pd.DataFrame(pca.explained_variance_ratio_)\n",
    "np.cumsum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=50,whiten=True)\n",
    "pca = pca.fit(data)\n",
    "dataPCA = pca.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA(copy=True, iterated_power='auto', n_components=50, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=True)\n"
     ]
    }
   ],
   "source": [
    "print(pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Model Selection ##\n",
    "\n",
    "Simple test to run multiple models against our data. First, with raw features. No PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split traing and test\n",
    "train = data[:1460]\n",
    "test = data[1460:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_squared_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Linear</th>\n",
       "      <td>1.649901e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>2.931139e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>2.398946e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>2.373996e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM RBF</th>\n",
       "      <td>2.068017e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM Linear</th>\n",
       "      <td>1.917665e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>1.791998e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bayesian Ridge</th>\n",
       "      <td>1.765186e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>1.702503e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hubber</th>\n",
       "      <td>1.701929e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                mean_squared_error\n",
       "Linear                1.649901e+18\n",
       "AdaBoost              2.931139e-02\n",
       "Bagging               2.398946e-02\n",
       "RandomForest          2.373996e-02\n",
       "SVM RBF               2.068017e-02\n",
       "SVM Linear            1.917665e-02\n",
       "Ridge                 1.791998e-02\n",
       "Bayesian Ridge        1.765186e-02\n",
       "Lasso                 1.702503e-02\n",
       "Hubber                1.701929e-02"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# R2 Score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "def lets_try(train,labels):\n",
    "    results={}\n",
    "    def test_model(clf):\n",
    "        \n",
    "        cv = KFold(n_splits=5,shuffle=True,random_state=45)\n",
    "        mse0 = make_scorer(mean_squared_error)\n",
    "        mse0_val_score = cross_val_score(clf, train, labels, cv=cv,scoring=mse0)\n",
    "        scores=[mse0_val_score.mean()]\n",
    "        return scores\n",
    "\n",
    "    clf = linear_model.LinearRegression()\n",
    "    results[\"Linear\"]=test_model(clf)\n",
    "    \n",
    "    clf = linear_model.Ridge()\n",
    "    results[\"Ridge\"]=test_model(clf)\n",
    "    \n",
    "    clf = linear_model.BayesianRidge()\n",
    "    results[\"Bayesian Ridge\"]=test_model(clf)\n",
    "    \n",
    "    clf = linear_model.HuberRegressor()\n",
    "    results[\"Hubber\"]=test_model(clf)\n",
    "    \n",
    "    clf = linear_model.Lasso(alpha=1e-4)\n",
    "    results[\"Lasso\"]=test_model(clf)\n",
    "    \n",
    "    clf = BaggingRegressor()\n",
    "    results[\"Bagging\"]=test_model(clf)\n",
    "    \n",
    "    clf = RandomForestRegressor()\n",
    "    results[\"RandomForest\"]=test_model(clf)\n",
    "    \n",
    "    clf = AdaBoostRegressor()\n",
    "    results[\"AdaBoost\"]=test_model(clf)\n",
    "    \n",
    "    clf = svm.SVR()\n",
    "    results[\"SVM RBF\"]=test_model(clf)\n",
    "    \n",
    "    clf = svm.SVR(kernel=\"linear\")\n",
    "    results[\"SVM Linear\"]=test_model(clf)\n",
    "    \n",
    "    results = pd.DataFrame.from_dict(results,orient='index')\n",
    "    results.columns=[\"mean_squared_error\"] \n",
    "    results=results.sort(columns=[\"mean_squared_error\"],ascending=False)\n",
    "    results.plot(kind=\"bar\",title=\"Model Scores\")\n",
    "    axes = plt.gca()\n",
    "    axes.set_ylim([0.5,1])\n",
    "    return results\n",
    "\n",
    "lets_try(train,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try the same but using data with PCA applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_squared_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.052711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>0.046489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.044015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM RBF</th>\n",
       "      <td>0.032512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM Linear</th>\n",
       "      <td>0.024561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear</th>\n",
       "      <td>0.024433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bayesian Ridge</th>\n",
       "      <td>0.024428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.024423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>0.024418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hubber</th>\n",
       "      <td>0.024176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                mean_squared_error\n",
       "AdaBoost                  0.052711\n",
       "Bagging                   0.046489\n",
       "RandomForest              0.044015\n",
       "SVM RBF                   0.032512\n",
       "SVM Linear                0.024561\n",
       "Linear                    0.024433\n",
       "Bayesian Ridge            0.024428\n",
       "Ridge                     0.024423\n",
       "Lasso                     0.024418\n",
       "Hubber                    0.024176"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split traing and test\n",
    "train = dataPCA[:1460]\n",
    "test = dataPCA[1460:]\n",
    "\n",
    "lets_try(train,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuberRegressor(alpha=100, epsilon=1.7, fit_intercept=True, max_iter=100,\n",
       "        tol=1e-10, warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = KFold(n_splits=5,shuffle=True,random_state=45)\n",
    "\n",
    "parameters = {'alpha': [1000,200,100,10],\n",
    "              'epsilon' : [1.2,1.25,1.50,1.7],\n",
    "              'tol' : [1e-10]}\n",
    "\n",
    "clf = linear_model.HuberRegressor()\n",
    "r2 = make_scorer(r2_score)\n",
    "grid_obj = GridSearchCV(clf, parameters, cv=cv,scoring=r2)\n",
    "grid_fit = grid_obj.fit(train, labels)\n",
    "best_clf = grid_fit.best_estimator_ \n",
    "\n",
    "best_clf.fit(train,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.02129803  0.01726948  0.02113003  0.03648716  0.03026765  0.01752579\n",
      "  0.02183388  0.01863285  0.03526825  0.02023543]\n",
      "0.0239948549804\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse1 = make_scorer(mean_squared_error)\n",
    "scores = cross_val_score(clf, train, labels, cv=10, scoring=mse1)\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "predictions_huber = best_clf.predict(test)\n",
    "predictions_huber = np.exp(predictions_huber)\n",
    "sub = pd.DataFrame({\n",
    "        \"Id\": ids,\n",
    "        \"SalePrice\": predictions_huber\n",
    "    })\n",
    "sub.to_csv(data_path+result_path+\"prices_huber1.csv\", index=False)\n",
    "#print(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM tranning and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmse_cv(model):\n",
    "    rmse= np.sqrt(-cross_val_score(model, train, labels, scoring=\"neg_mean_squared_error\", cv = 5))\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on all data: \n",
      "0.155331921673\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Training on all data: ')\n",
    "model_svm = svm.SVR(kernel=\"linear\", C=3,)\n",
    "model_svm.fit(train, labels)\n",
    "\n",
    "\n",
    "\n",
    "cv_rmse_svm = rmse_cv(model_svm).mean()\n",
    "print (cv_rmse_svm)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model_svm.predict(test)\n",
    "predictions_svm = np.exp(predictions)\n",
    "sub = pd.DataFrame({\n",
    "        \"Id\": ids,\n",
    "        \"SalePrice\": predictions_svm\n",
    "    })\n",
    "sub.to_csv(data_path+result_path+\"prices_svm1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.02345859  0.01640437  0.02317852  0.03338032  0.029027    0.0226658\n",
      "  0.02265506  0.02255614  0.03490317  0.02274871]\n",
      "0.0250977686718\n"
     ]
    }
   ],
   "source": [
    "mse1 = make_scorer(mean_squared_error)\n",
    "scores = cross_val_score(clf, train, labels, cv=10, scoring=mse1)\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Neural Network\n",
    "---------------------\n",
    "\n",
    "Now I am going to try a simple neural network, to see if i can improve the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shape the labels\n",
    "labels_nl = labels\n",
    "labels_nl = labels_nl.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "r2 = tflearn.R2()\n",
    "net = tflearn.input_data(shape=[None, train.shape[1]])\n",
    "net = tflearn.fully_connected(net, 30, activation='linear')\n",
    "net = tflearn.fully_connected(net, 10, activation='linear')\n",
    "net = tflearn.fully_connected(net, 1, activation='linear')\n",
    "sgd = tflearn.SGD(learning_rate=0.1, lr_decay=0.01, decay_step=100)\n",
    "net = tflearn.regression(net, optimizer=sgd,loss='mean_square',metric=r2)\n",
    "model = tflearn.DNN(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(train, labels_nl,show_metric=True,validation_set=0.2,shuffle=True,n_epoch=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "\n",
    "predictions_huber = best_clf.predict(test)\n",
    "predictions_DNN = model.predict(test)\n",
    "predictions_huber = np.exp(predictions_huber)\n",
    "predictions_DNN = np.exp(predictions_DNN)\n",
    "predictions_DNN = predictions_DNN.reshape(-1,)\n",
    "\n",
    "sub = pd.DataFrame({\n",
    "        \"Id\": ids,\n",
    "        \"SalePrice\": predictions_DNN\n",
    "    })\n",
    "\n",
    "sub.to_csv(\"prices_submission.csv\", index=False)\n",
    "#print(sub)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
