{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The idea is:**\n",
    "\n",
    " - Feature reduction with PCA\n",
    " - Data transformation (log, hot encoding, nan)\n",
    " - Test different regression models\n",
    "\n",
    "**Things found:**\n",
    "\n",
    "- Applying log transformation really increases the accuracy.\n",
    "- Using PCA with 36 components makes the learning and testing much (much much) faster.\n",
    "- Removing columns with more than 1000 NaNs gives better result than applying \"mean\" to them.\n",
    "- There are outliers. Instead of removing them, using Huber seems to provide a good result. Huber is a model robust to outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results.csv\n",
      "test.csv\n",
      "test_new.csv\n",
      "train.csv\n",
      "train_new.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "#import tflearn\n",
    "#import tensorflow as tf\n",
    "import seaborn\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "train1=\"/home/barlesh/Projects/Hasaka/data/train_new.csv\"\n",
    "test1=\"/home/barlesh/Projects/Hasaka/data/test_new.csv\"\n",
    "out1=\"/home/barlesh/Projects/Hasaka/data/results.csv\"\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"/home/barlesh/Projects/Hasaka/data\"]).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Load ##\n",
    "\n",
    "I mix data and test to manipulate all the data just once. SalePrice is extracted to its own variable \"labels\". Finally, SalesPrice is remove from data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(train1)\n",
    "labels=train[\"SalePrice\"]\n",
    "test = pd.read_csv(test1)\n",
    "data = pd.concat([train,test],ignore_index=True)\n",
    "data = data.drop(\"SalePrice\", 1)\n",
    "ids = test[\"Id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>0</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>0</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>0</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>0</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>0</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Id  MSSubClass MSZoning  LotFrontage  LotArea Street  Alley  \\\n",
       "0           0   1          60       RL         65.0     8450   Pave      0   \n",
       "1           1   2          20       RL         80.0     9600   Pave      0   \n",
       "2           2   3          60       RL         68.0    11250   Pave      0   \n",
       "3           3   4          70       RL         60.0     9550   Pave      0   \n",
       "4           4   5          60       RL         84.0    14260   Pave      0   \n",
       "\n",
       "  LotShape LandContour    ...     PoolArea PoolQC Fence MiscFeature MiscVal  \\\n",
       "0      Reg         Lvl    ...            0   None  None        None       0   \n",
       "1      Reg         Lvl    ...            0   None  None        None       0   \n",
       "2      IR1         Lvl    ...            0   None  None        None       0   \n",
       "3      IR1         Lvl    ...            0   None  None        None       0   \n",
       "4      IR1         Lvl    ...            0   None  None        None       0   \n",
       "\n",
       "  MoSold YrSold SaleType  SaleCondition  SalePrice  \n",
       "0      2   2008       WD         Normal     208500  \n",
       "1      5   2007       WD         Normal     181500  \n",
       "2      9   2008       WD         Normal     223500  \n",
       "3      2   2006       WD        Abnorml     140000  \n",
       "4     12   2008       WD         Normal     250000  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1460"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of rows in train\n",
    "train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2919"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of rows in total\n",
    "data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of NaNs each column has.\n",
    "nans=pd.isnull(data).sum()\n",
    "nans[nans>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove id and columns with more than a thousand missing values\n",
    "data=data.drop(\"Id\", 1)\n",
    "data=data.drop(\"Alley\", 1)\n",
    "data=data.drop(\"Fence\", 1)\n",
    "data=data.drop(\"MiscFeature\", 1)\n",
    "data=data.drop(\"PoolQC\", 1)\n",
    "data=data.drop(\"FireplaceQu\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "object     40\n",
       "int64      26\n",
       "float64     9\n",
       "dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the column types\n",
    "data.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Manipulation ##\n",
    "\n",
    "- Apply hot encoding, convert categorical variable into dummy/indicator variables.\n",
    "- Fill NaN with median for that column.\n",
    "- Log transformation.\n",
    "- Change -inf to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_columns = data.columns.values\n",
    "non_categorical = [\"LotFrontage\", \"LotArea\", \"MasVnrArea\", \"BsmtFinSF1\", \n",
    "                   \"BsmtFinSF2\", \"BsmtUnfSF\", \"TotalBsmtSF\", \"1stFlrSF\", \n",
    "                   \"2ndFlrSF\", \"LowQualFinSF\", \"GrLivArea\", \"GarageArea\", \n",
    "                   \"WoodDeckSF\", \"OpenPorchSF\", \"EnclosedPorch\", \"3SsnPorch\", \n",
    "                   \"ScreenPorch\",\"PoolArea\", \"MiscVal\"]\n",
    "\n",
    "categorical = [value for value in all_columns if value not in non_categorical]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One Hot Encoding and nan transformation\n",
    "data = pd.get_dummies(data)\n",
    "\n",
    "imp = Imputer(missing_values='NaN', strategy='most_frequent', axis=0)\n",
    "data = imp.fit_transform(data)\n",
    "\n",
    "# Log transformation\n",
    "data = np.log(data)\n",
    "labels = np.log(labels)\n",
    "\n",
    "# Change -inf to 0 again\n",
    "data[data==-np.inf]=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature reduction ##\n",
    "\n",
    "There are many features, so I am going to use PCA to reduce them. The idea is to start with n_components = number of columns. Then select the number of components that add up to 1 variance_ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.22082383,  0.39898977,  0.51338389,  0.61063673,  0.68641341,\n",
       "        0.75337537,  0.8081475 ,  0.8539118 ,  0.88815001,  0.91427362,\n",
       "        0.93521893,  0.95212872,  0.96146401,  0.96877832,  0.97461264,\n",
       "        0.9801822 ,  0.98528517,  0.989343  ,  0.99153157,  0.99360662,\n",
       "        0.99516051,  0.99607108,  0.9969237 ,  0.99764987,  0.99832897,\n",
       "        0.99883967,  0.99923139,  0.99949113,  0.99972032,  0.99989236,\n",
       "        0.99995277,  0.9999978 ,  0.99999931,  0.99999999,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,  1.        ])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(whiten=True)\n",
    "pca.fit(data)\n",
    "variance = pd.DataFrame(pca.explained_variance_ratio_)\n",
    "np.cumsum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=36,whiten=True)\n",
    "pca = pca.fit(data)\n",
    "dataPCA = pca.transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Model Selection ##\n",
    "\n",
    "Simple test to run multiple models against our data. First, with raw features. No PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split traing and test\n",
    "train = data[:1460]\n",
    "test = data[1460:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R Square Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Linear</th>\n",
       "      <td>0.856139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>0.855225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bayesian Ridge</th>\n",
       "      <td>0.854962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM Linear</th>\n",
       "      <td>0.849812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.846358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>0.846228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.839068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hubber</th>\n",
       "      <td>0.831860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM RBF</th>\n",
       "      <td>0.810558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.798159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                R Square Score\n",
       "Linear                0.856139\n",
       "Lasso                 0.855225\n",
       "Bayesian Ridge        0.854962\n",
       "SVM Linear            0.849812\n",
       "RandomForest          0.846358\n",
       "Bagging               0.846228\n",
       "Ridge                 0.839068\n",
       "Hubber                0.831860\n",
       "SVM RBF               0.810558\n",
       "AdaBoost              0.798159"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# R2 Score\n",
    "\n",
    "def lets_try(train,labels):\n",
    "    results={}\n",
    "    def test_model(clf):\n",
    "        \n",
    "        cv = KFold(n_splits=5,shuffle=True,random_state=45)\n",
    "        r2 = make_scorer(r2_score)\n",
    "        r2_val_score = cross_val_score(clf, train, labels, cv=cv,scoring=r2)\n",
    "        scores=[r2_val_score.mean()]\n",
    "        return scores\n",
    "\n",
    "    clf = linear_model.LinearRegression()\n",
    "    results[\"Linear\"]=test_model(clf)\n",
    "    \n",
    "    clf = linear_model.Ridge()\n",
    "    results[\"Ridge\"]=test_model(clf)\n",
    "    \n",
    "    clf = linear_model.BayesianRidge()\n",
    "    results[\"Bayesian Ridge\"]=test_model(clf)\n",
    "    \n",
    "    clf = linear_model.HuberRegressor()\n",
    "    results[\"Hubber\"]=test_model(clf)\n",
    "    \n",
    "    clf = linear_model.Lasso(alpha=1e-4)\n",
    "    results[\"Lasso\"]=test_model(clf)\n",
    "    \n",
    "    clf = BaggingRegressor()\n",
    "    results[\"Bagging\"]=test_model(clf)\n",
    "    \n",
    "    clf = RandomForestRegressor()\n",
    "    results[\"RandomForest\"]=test_model(clf)\n",
    "    \n",
    "    clf = AdaBoostRegressor()\n",
    "    results[\"AdaBoost\"]=test_model(clf)\n",
    "    \n",
    "    clf = svm.SVR()\n",
    "    results[\"SVM RBF\"]=test_model(clf)\n",
    "    \n",
    "    clf = svm.SVR(kernel=\"linear\")\n",
    "    results[\"SVM Linear\"]=test_model(clf)\n",
    "    \n",
    "    results = pd.DataFrame.from_dict(results,orient='index')\n",
    "    results.columns=[\"R Square Score\"] \n",
    "    results=results.sort(columns=[\"R Square Score\"],ascending=False)\n",
    "    results.plot(kind=\"bar\",title=\"Model Scores\")\n",
    "    axes = plt.gca()\n",
    "    axes.set_ylim([0.5,1])\n",
    "    return results\n",
    "\n",
    "lets_try(train,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try the same but using data with PCA applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R Square Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Hubber</th>\n",
       "      <td>0.861132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM Linear</th>\n",
       "      <td>0.859394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bayesian Ridge</th>\n",
       "      <td>0.856218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>0.856190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.856165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear</th>\n",
       "      <td>0.856139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM RBF</th>\n",
       "      <td>0.784373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.710882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>0.699284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.660673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                R Square Score\n",
       "Hubber                0.861132\n",
       "SVM Linear            0.859394\n",
       "Bayesian Ridge        0.856218\n",
       "Lasso                 0.856190\n",
       "Ridge                 0.856165\n",
       "Linear                0.856139\n",
       "SVM RBF               0.784373\n",
       "RandomForest          0.710882\n",
       "Bagging               0.699284\n",
       "AdaBoost              0.660673"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split traing and test\n",
    "train = dataPCA[:1460]\n",
    "test = dataPCA[1460:]\n",
    "\n",
    "lets_try(train,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "cv = KFold(n_splits=5,shuffle=True,random_state=45)\n",
    "\n",
    "parameters = {'n_estimators': [100,200,300, ], 'max_features': [None,] ,'n_jobs': [5,], 'max_depth': [2,4,6,8,] }\n",
    "mse1 = make_scorer(mean_squared_error)\n",
    "\n",
    "clf = RandomForestRegressor()\n",
    "r2 = make_scorer(r2_score)\n",
    "grid_obj = GridSearchCV(clf, parameters, cv=cv,scoring=r2)\n",
    "grid_fit = grid_obj.fit(train, labels)\n",
    "best_clf = grid_fit.best_estimator_\n",
    "\n",
    "best_clf.fit(train,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=8,\n",
       "           max_features=None, max_leaf_nodes=None,\n",
       "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=300, n_jobs=5, oob_score=False, random_state=None,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "best_clf.fit(train,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.03225796  0.03554197  0.04319547  0.05179107  0.0560194   0.03820767\n",
      "  0.03859552  0.0404297   0.05255436  0.03922798]\n",
      "0.0427821109159\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse1 = make_scorer(mean_squared_error)\n",
    "scores = cross_val_score(clf, train, labels, cv=10, scoring=mse1)\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "predictions_forest = best_clf.predict(test)\n",
    "\n",
    "# reverse log(x+1)\n",
    "predictions_forest = np.exp(predictions_forest)\n",
    "\n",
    "\n",
    "\n",
    "sub = pd.DataFrame({\n",
    "        \"Id\": ids,\n",
    "        \"SalePrice\": predictions_forest\n",
    "    })\n",
    "\n",
    "sub.to_csv(out1, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Simple Neural Network\n",
    "---------------------\n",
    "\n",
    "Now I am going to try a simple neural network, to see if i can improve the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shape the labels\n",
    "labels_nl = labels\n",
    "labels_nl = labels_nl.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "r2 = tflearn.R2()\n",
    "net = tflearn.input_data(shape=[None, train.shape[1]])\n",
    "net = tflearn.fully_connected(net, 30, activation='linear')\n",
    "net = tflearn.fully_connected(net, 10, activation='linear')\n",
    "net = tflearn.fully_connected(net, 1, activation='linear')\n",
    "sgd = tflearn.SGD(learning_rate=0.1, lr_decay=0.01, decay_step=100)\n",
    "net = tflearn.regression(net, optimizer=sgd,loss='mean_square',metric=r2)\n",
    "model = tflearn.DNN(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(train, labels_nl,show_metric=True,validation_set=0.2,shuffle=True,n_epoch=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "\n",
    "predictions_huber = best_clf.predict(test)\n",
    "predictions_DNN = model.predict(test)\n",
    "predictions_huber = np.exp(predictions_huber)\n",
    "predictions_DNN = np.exp(predictions_DNN)\n",
    "predictions_DNN = predictions_DNN.reshape(-1,)\n",
    "\n",
    "sub = pd.DataFrame({\n",
    "        \"Id\": ids,\n",
    "        \"SalePrice\": predictions_DNN\n",
    "    })\n",
    "\n",
    "sub.to_csv(\"prices_submission.csv\", index=False)\n",
    "#print(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
